{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857352bf",
   "metadata": {},
   "source": [
    "# Thai OCR Dataset Converter for EasyOCR\n",
    "\n",
    "**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**\n",
    "Notebook ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Thai OCR Dataset ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà EasyOCR ‡πÉ‡∏ä‡πâ\n",
    "\n",
    "**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:**\n",
    "1. üìö Import libraries\n",
    "2. üìÅ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ path ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏≠‡∏≠‡∏Å\n",
    "3. üìä ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á\n",
    "4. üîÑ ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö EasyOCR\n",
    "5. üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡πâ‡∏ß\n",
    "6. ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "\n",
    "**‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:**\n",
    "```\n",
    "output_dataset/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ labels.txt\n",
    "‚îî‚îÄ‚îÄ val/\n",
    "    ‚îú‚îÄ‚îÄ images/ \n",
    "    ‚îî‚îÄ‚îÄ labels.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee0467",
   "metadata": {},
   "source": [
    "## üìö 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f49c3567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Libraries imported successfully!\n",
      "‚è∞ Current time: 2025-06-29 05:02:04\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split # pip install scikit-learn\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")\n",
    "print(f\"‚è∞ Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ebc67",
   "metadata": {},
   "source": [
    "## üìÅ 2. Set Input and Output File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539ad2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Input dataset: all_data/thai_lang_ocr_dataset\n",
      "üìÅ Output dataset: all_data/thai_easyocr_format\n",
      "üìä Split ratio: Train 80% | Val 20%\n",
      "‚úÖ Input directory exists\n"
     ]
    }
   ],
   "source": [
    "# üîß INPUT PATHS - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
    "INPUT_BASE = \"all_data/thai_lang_ocr_dataset\"  # üìÅ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á\n",
    "INPUT_TRAIN_LIST = os.path.join(INPUT_BASE, \"train_list.txt\")\n",
    "INPUT_VAL_LIST = os.path.join(INPUT_BASE, \"val_list.txt\")\n",
    "\n",
    "# üéØ OUTPUT PATHS\n",
    "OUTPUT_BASE = \"all_data/thai_easyocr_format\"  # üìÅ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "OUTPUT_TRAIN_DIR = os.path.join(OUTPUT_BASE, \"train\")\n",
    "OUTPUT_VAL_DIR = os.path.join(OUTPUT_BASE, \"val\")\n",
    "\n",
    "# üìä SETTINGS\n",
    "TRAIN_RATIO = 0.8  # 80% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training\n",
    "VAL_RATIO = 0.2    # 20% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö validation\n",
    "RANDOM_SEED = 42   # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ\n",
    "\n",
    "print(f\"üìÅ Input dataset: {INPUT_BASE}\")\n",
    "print(f\"üìÅ Output dataset: {OUTPUT_BASE}\")\n",
    "print(f\"üìä Split ratio: Train {TRAIN_RATIO*100:.0f}% | Val {VAL_RATIO*100:.0f}%\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "if os.path.exists(INPUT_BASE):\n",
    "    print(f\"‚úÖ Input directory exists\")\n",
    "else:\n",
    "    print(f\"‚ùå Input directory not found: {INPUT_BASE}\")\n",
    "    print(\"   Please update INPUT_BASE path above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed73b14",
   "metadata": {},
   "source": [
    "## üìä 3. Read and Inspect Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5334ddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Reading input files...\n",
      "üìä Data summary:\n",
      "   Train data: 197995 samples\n",
      "   Val data: 2000 samples\n",
      "   Total: 199995 samples\n",
      "\n",
      "üìù Sample from train data:\n",
      "   1. Image: 0/ILSVRC2012_val_00012640_12215.jpg\n",
      "      Text: ‡∏î‡πâ‡∏≤‡∏ô‡∏£‡∏≠‡∏á‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤\n",
      "      File exists: ‚úÖ\n",
      "\n",
      "   2. Image: 0/ILSVRC2012_val_00013060_17187.jpg\n",
      "      Text: ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á\n",
      "      File exists: ‚úÖ\n",
      "\n",
      "   3. Image: 0/ILSVRC2012_val_00014897_10839.jpg\n",
      "      Text: ‡πÇ‡∏î‡∏¢‡∏ö‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏ò‡∏≠\n",
      "      File exists: ‚úÖ\n",
      "\n",
      "üìù Sample from val data:\n",
      "   1. Image: 1/ILSVRC2012_val_00018359_10720.jpg\n",
      "      Text: gia\n",
      "      File exists: ‚úÖ\n",
      "\n",
      "   2. Image: 1/ILSVRC2012_val_00011177_2324.jpg\n",
      "      Text: (imperialism)\n",
      "      File exists: ‚úÖ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_label_file(file_path):\n",
    "    \"\"\"‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå label ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡∏≠‡∏á (image_path, text)\"\"\"\n",
    "    data = []\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    parts = line.split('\\t')\n",
    "                    if len(parts) >= 2:\n",
    "                        image_path = parts[0].replace('th_img/', '')  # ‡∏•‡∏ö 'th_img/' ‡∏≠‡∏≠‡∏Å\n",
    "                        text = parts[1]\n",
    "                        data.append((image_path, text))\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è  Line {line_num} has incorrect format: {line}\")\n",
    "    return data\n",
    "\n",
    "# ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á\n",
    "print(\"üìñ Reading input files...\")\n",
    "train_data = read_label_file(INPUT_TRAIN_LIST)\n",
    "val_data = read_label_file(INPUT_VAL_LIST)\n",
    "\n",
    "print(f\"üìä Data summary:\")\n",
    "print(f\"   Train data: {len(train_data)} samples\")\n",
    "print(f\"   Val data: {len(val_data)} samples\")\n",
    "print(f\"   Total: {len(train_data) + len(val_data)} samples\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "if train_data:\n",
    "    print(f\"\\nüìù Sample from train data:\")\n",
    "    for i, (img_path, text) in enumerate(train_data[:3]):\n",
    "        print(f\"   {i+1}. Image: {img_path}\")\n",
    "        print(f\"      Text: {text}\")\n",
    "        \n",
    "        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "        full_img_path = os.path.join(INPUT_BASE, img_path)\n",
    "        exists = \"‚úÖ\" if os.path.exists(full_img_path) else \"‚ùå\"\n",
    "        print(f\"      File exists: {exists}\")\n",
    "        print()\n",
    "\n",
    "if val_data:\n",
    "    print(f\"üìù Sample from val data:\")\n",
    "    for i, (img_path, text) in enumerate(val_data[:2]):\n",
    "        print(f\"   {i+1}. Image: {img_path}\")\n",
    "        print(f\"      Text: {text}\")\n",
    "        \n",
    "        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "        full_img_path = os.path.join(INPUT_BASE, img_path)\n",
    "        exists = \"‚úÖ\" if os.path.exists(full_img_path) else \"‚ùå\"\n",
    "        print(f\"      File exists: {exists}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63c01c",
   "metadata": {},
   "source": [
    "## üîÑ 4. Transform Data to EasyOCR Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1c769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting to EasyOCR format...\n",
      "üìä Total: 199995 samples\n",
      "Train: 159996 | Val: 39999\n",
      "üîÑ Creating train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159996/159996 [01:41<00:00, 1571.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Created 159996 samples in all_data/thai_easyocr_format/train\n",
      "   üìÑ Generated labels.txt (159996 entries)\n",
      "   üìä Generated labels.csv (159996 entries)\n",
      "üîÑ Creating val set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39999/39999 [00:25<00:00, 1596.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Created 39999 samples in all_data/thai_easyocr_format/val\n",
      "   üìÑ Generated labels.txt (39999 entries)\n",
      "   üìä Generated labels.csv (39999 entries)\n",
      "\n",
      "‚úÖ Conversion Complete!\n",
      "üìä Summary: Train: 159996 | Val: 39999\n",
      "üìÅ Output: all_data/thai_easyocr_format\n",
      "üéØ Both labels.txt and labels.csv files created for EasyOCR compatibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_to_easyocr_format():\n",
    "    \"\"\"‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà EasyOCR ‡πÉ‡∏ä‡πâ\"\"\"\n",
    "    \n",
    "    # üöÄ FAST CONVERSION - EasyOCR Format\n",
    "    print(\"üîÑ Converting to EasyOCR format...\")\n",
    "\n",
    "    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "    all_data = train_data + val_data\n",
    "    print(f\"üìä Total: {len(all_data)} samples\")\n",
    "\n",
    "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 80-20\n",
    "    random.seed(RANDOM_SEED)\n",
    "    random.shuffle(all_data)\n",
    "    split_idx = int(len(all_data) * 0.8)\n",
    "    train_set = all_data[:split_idx]\n",
    "    val_set = all_data[split_idx:]\n",
    "\n",
    "    print(f\"Train: {len(train_set)} | Val: {len(val_set)}\")\n",
    "\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå\n",
    "    os.makedirs(f\"{OUTPUT_BASE}/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{OUTPUT_BASE}/val\", exist_ok=True)\n",
    "\n",
    "    def create_dataset(data_list, output_dir, prefix):\n",
    "        \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡πá‡∏ß ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏±‡πâ‡∏á labels.txt ‡πÅ‡∏•‡∏∞ labels.csv\"\"\"\n",
    "        labels_txt = []\n",
    "        labels_csv_data = []\n",
    "        count = 0\n",
    "        \n",
    "        for i, (img_path, text) in enumerate(tqdm(data_list, desc=f\"Processing {prefix}\")):\n",
    "            source = os.path.join(INPUT_BASE, img_path)\n",
    "            if os.path.exists(source):\n",
    "                # ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏π‡∏õ\n",
    "                ext = os.path.splitext(img_path)[1] or '.jpg'\n",
    "                new_name = f\"{prefix}_{i:06d}{ext}\"\n",
    "                target = os.path.join(output_dir, new_name)\n",
    "                shutil.copy2(source, target)\n",
    "                \n",
    "                # ‡πÄ‡∏û‡∏¥‡πà‡∏° label ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö labels.txt (tab-separated)\n",
    "                labels_txt.append(f\"{new_name}\\t{text}\")\n",
    "                \n",
    "                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö labels.csv \n",
    "                labels_csv_data.append([new_name, text])\n",
    "                \n",
    "                count += 1\n",
    "        \n",
    "        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô labels.txt\n",
    "        with open(f\"{output_dir}/labels.txt\", 'w', encoding='utf8') as f:\n",
    "            f.write('\\n'.join(labels_txt))\n",
    "        \n",
    "        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô labels.csv ‡∏û‡∏£‡πâ‡∏≠‡∏° header\n",
    "        df = pd.DataFrame(labels_csv_data, columns=['filename', 'words'])\n",
    "        df.to_csv(f\"{output_dir}/labels.csv\", index=False, encoding='utf8')\n",
    "        \n",
    "        print(f\"   ‚úÖ Created {count} samples in {output_dir}\")\n",
    "        print(f\"   üìÑ Generated labels.txt ({len(labels_txt)} entries)\")\n",
    "        print(f\"   üìä Generated labels.csv ({len(labels_csv_data)} entries)\")\n",
    "        \n",
    "        return count\n",
    "\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á datasets\n",
    "    print(\"üîÑ Creating train set...\")\n",
    "    train_count = create_dataset(train_set, f\"{OUTPUT_BASE}/train\", \"train\")\n",
    "\n",
    "    print(\"üîÑ Creating val set...\")\n",
    "    val_count = create_dataset(val_set, f\"{OUTPUT_BASE}/val\", \"val\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Conversion Complete!\")\n",
    "    print(f\"üìä Summary: Train: {train_count} | Val: {val_count}\")\n",
    "    print(f\"üìÅ Output: {OUTPUT_BASE}\")\n",
    "    print(f\"üéØ Both labels.txt and labels.csv files created for EasyOCR compatibility\")\n",
    "    \n",
    "    return train_count, val_count\n",
    "\n",
    "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á\n",
    "if train_data or val_data:\n",
    "    train_count, val_count = convert_to_easyocr_format()\n",
    "else:\n",
    "    print(\"‚ùå No data to convert. Please check input files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3b07a",
   "metadata": {},
   "source": [
    "## üíæ 5. Dataset Structure Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6cdcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Dataset Structure:\n",
      "all_data/thai_easyocr_format/\n",
      "üìÅ all_data/thai_easyocr_format/\n",
      "‚îú‚îÄ‚îÄ train/ (159996 images + labels.txt)\n",
      "‚îî‚îÄ‚îÄ val/ (39999 images + labels.txt)\n",
      "\n",
      "üéØ For EasyOCR training, use:\n",
      "'train_data': 'all_data/thai_easyocr_format',\n",
      "'valid_data': 'all_data/thai_easyocr_format',\n",
      "'select_data': 'train',\n"
     ]
    }
   ],
   "source": [
    "def show_dataset_structure():\n",
    "    \"\"\"‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á dataset ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô\"\"\"\n",
    "    \n",
    "    print(\"üìÅ Dataset Structure:\")\n",
    "    print(f\"{OUTPUT_BASE}/\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå train\n",
    "    train_images_dir = os.path.join(OUTPUT_TRAIN_DIR, \"images\")\n",
    "    train_labels_file = os.path.join(OUTPUT_TRAIN_DIR, \"labels.txt\")\n",
    "    \n",
    "    if os.path.exists(train_images_dir):\n",
    "        train_image_count = len([f for f in os.listdir(train_images_dir) \n",
    "                               if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"‚îú‚îÄ‚îÄ train/\")\n",
    "        print(f\"‚îÇ   ‚îú‚îÄ‚îÄ images/ ({train_image_count} images)\")\n",
    "        \n",
    "        if os.path.exists(train_labels_file):\n",
    "            with open(train_labels_file, 'r', encoding='utf8') as f:\n",
    "                train_label_count = len(f.readlines())\n",
    "            print(f\"‚îÇ   ‚îî‚îÄ‚îÄ labels.txt ({train_label_count} entries)\")\n",
    "        else:\n",
    "            print(f\"‚îÇ   ‚îî‚îÄ‚îÄ labels.txt (‚ùå not found)\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå val\n",
    "    val_images_dir = os.path.join(OUTPUT_VAL_DIR, \"images\")\n",
    "    val_labels_file = os.path.join(OUTPUT_VAL_DIR, \"labels.txt\")\n",
    "    \n",
    "    if os.path.exists(val_images_dir):\n",
    "        val_image_count = len([f for f in os.listdir(val_images_dir) \n",
    "                             if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"‚îî‚îÄ‚îÄ val/\")\n",
    "        print(f\"    ‚îú‚îÄ‚îÄ images/ ({val_image_count} images)\")\n",
    "        \n",
    "        if os.path.exists(val_labels_file):\n",
    "            with open(val_labels_file, 'r', encoding='utf8') as f:\n",
    "                val_label_count = len(f.readlines())\n",
    "            print(f\"    ‚îî‚îÄ‚îÄ labels.txt ({val_label_count} entries)\")\n",
    "        else:\n",
    "            print(f\"    ‚îî‚îÄ‚îÄ labels.txt (‚ùå not found)\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á dataset\n",
    "if os.path.exists(OUTPUT_BASE):\n",
    "    show_dataset_structure()\n",
    "    \n",
    "    # üìä QUICK CHECK\n",
    "    train_images = len([f for f in os.listdir(f\"{OUTPUT_BASE}/train\") if f.endswith(('.jpg', '.png'))])\n",
    "    val_images = len([f for f in os.listdir(f\"{OUTPUT_BASE}/val\") if f.endswith(('.jpg', '.png'))])\n",
    "    \n",
    "    print(f\"üìÅ {OUTPUT_BASE}/\")\n",
    "    print(f\"‚îú‚îÄ‚îÄ train/ ({train_images} images + labels.txt)\")\n",
    "    print(f\"‚îî‚îÄ‚îÄ val/ ({val_images} images + labels.txt)\")\n",
    "    \n",
    "    print(f\"\\nüéØ For EasyOCR training, use:\")\n",
    "    print(f\"'train_data': '{OUTPUT_BASE}',\")\n",
    "    print(f\"'valid_data': '{OUTPUT_BASE}',\")\n",
    "    print(f\"'select_data': 'train',\")\n",
    "else:\n",
    "    print(\"‚ùå Output dataset not found. Please run the transformation step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668ae80",
   "metadata": {},
   "source": [
    "## ‚úÖ 6. Verify Output Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_output_dataset():\n",
    "    \"\"\"‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á dataset ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô\"\"\"\n",
    "    \n",
    "    print(\"üîç Verifying output dataset...\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ output dataset ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á\n",
    "    if os.path.exists(OUTPUT_BASE):\n",
    "        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö training data\n",
    "        train_images_dir = os.path.join(OUTPUT_BASE, \"train\")\n",
    "        train_images = [f for f in os.listdir(train_images_dir) \n",
    "                       if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        with open(os.path.join(train_images_dir, 'labels.txt'), 'r', encoding='utf8') as f:\n",
    "            train_labels = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "        print(f\"\\nüìä Training Data Verification:\")\n",
    "        print(f\"   üì∏ Images: {len(train_images)}\")\n",
    "        print(f\"   üè∑Ô∏è  Labels: {len(train_labels)}\")\n",
    "        \n",
    "        if len(train_images) == len(train_labels):\n",
    "            print(f\"   ‚úÖ Images and labels count match\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Images and labels count mismatch\")\n",
    "        \n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á labels\n",
    "        print(f\"   üìù Sample labels:\")\n",
    "        for i, label in enumerate(train_labels[:3]):\n",
    "            print(f\"      {i+1}. {label}\")\n",
    "        \n",
    "        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö validation data\n",
    "        val_images_dir = os.path.join(OUTPUT_BASE, \"val\")\n",
    "        val_images = [f for f in os.listdir(val_images_dir) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        with open(os.path.join(val_images_dir, 'labels.txt'), 'r', encoding='utf8') as f:\n",
    "            val_labels = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "        print(f\"\\nüìä Validation Data Verification:\")\n",
    "        print(f\"   üì∏ Images: {len(val_images)}\")\n",
    "        print(f\"   üè∑Ô∏è  Labels: {len(val_labels)}\")\n",
    "        \n",
    "        if len(val_images) == len(val_labels):\n",
    "            print(f\"   ‚úÖ Images and labels count match\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Images and labels count mismatch\")\n",
    "        \n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á labels\n",
    "        print(f\"   üìù Sample labels:\")\n",
    "        for i, label in enumerate(val_labels[:3]):\n",
    "            print(f\"      {i+1}. {label}\")\n",
    "        \n",
    "        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "        total_train = len(train_images)\n",
    "        total_val = len(val_images)\n",
    "        total_all = total_train + total_val\n",
    "        \n",
    "        print(f\"\\nüéØ Final Summary:\")\n",
    "        print(f\"   üìä Total dataset: {total_all} samples\")\n",
    "        print(f\"   üèãÔ∏è  Training: {total_train} samples ({total_train/total_all*100:.1f}%)\" if total_all > 0 else \"   üèãÔ∏è  Training: 0 samples\")\n",
    "        print(f\"   üî¨ Validation: {total_val} samples ({total_val/total_all*100:.1f}%)\" if total_all > 0 else \"   üî¨ Validation: 0 samples\")\n",
    "        \n",
    "        if total_all > 0:\n",
    "            print(f\"   ‚úÖ Dataset ready for EasyOCR training!\")\n",
    "            print(f\"   üìÅ Location: {OUTPUT_BASE}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Dataset verification failed\")\n",
    "    else:\n",
    "        print(\"‚ùå No dataset found\")\n",
    "\n",
    "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö\n",
    "verify_output_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
