{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4a8929",
   "metadata": {},
   "source": [
    "# EasyOCR Thai Training Notebook\n",
    "\n",
    "**Quick Setup:**\n",
    "1. Config ในส่วน \"🔧 CONFIG\" \n",
    "2. Check dataset ในส่วน \"📊 VALIDATION\"\n",
    "3. Start training ในส่วน \"🚀 TRAINING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92115e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# ⚙️ SETUP & IMPORTS\n",
    "import os, sys, time, torch, yaml, pandas as pd, numpy as np\n",
    "from datetime import datetime\n",
    "import torch.backends.cudnn as cudnn\n",
    "from train import train\n",
    "from utils import AttrDict\n",
    "\n",
    "# Configure CUDNN for performance\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False\n",
    "\n",
    "# Quick system check\n",
    "print(f\"🐍 PyTorch: {torch.__version__}\")\n",
    "print(f\"🔥 CUDA: {'✅' if torch.cuda.is_available() else '❌'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"📱 GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef34d4",
   "metadata": {},
   "source": [
    "## ⚙️ SYSTEM SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940816ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ No CUDA available, using CPU\n",
      "🎯 Final device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 🎯 GPU SELECTION\n",
    "if torch.cuda.is_available():\n",
    "    GPU_ID = 0  # 🔧 CHANGE THIS TO SELECT DIFFERENT GPU\n",
    "    device = torch.device(f'cuda:{GPU_ID}')\n",
    "    torch.cuda.set_device(GPU_ID)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"✅ Using GPU {GPU_ID}: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"⚠️  Using CPU (no CUDA available)\")\n",
    "print(f\"🎯 Final device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📝 LOAD BASE CONFIG\n",
    "config_file = 'config_files/thai_auto_config.yaml'\n",
    "\n",
    "with open(config_file, 'r', encoding='utf8') as f:\n",
    "    opt = AttrDict(yaml.safe_load(f))\n",
    "\n",
    "# Auto-generate character set from training data\n",
    "all_chars = set()\n",
    "labels_path = os.path.join(opt.train_data, opt.select_data, 'labels.csv')\n",
    "if os.path.exists(labels_path):\n",
    "    df = pd.read_csv(labels_path, sep='^([^,]+),', engine='python', \n",
    "                     usecols=['filename', 'words'], keep_default_na=False)\n",
    "    for text in df['words']:\n",
    "        all_chars.update(text)\n",
    "\n",
    "# Build complete character set\n",
    "numbers = opt.get('number', '')\n",
    "symbols = opt.get('symbol', '')\n",
    "opt.character = numbers + symbols + ''.join(sorted(list(all_chars)))\n",
    "opt.device = str(device)\n",
    "\n",
    "print(f\"📋 Base config loaded: {opt.experiment_name}\")\n",
    "print(f\"🔤 Character set: {len(opt.character)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592692a",
   "metadata": {},
   "source": [
    "## 🔧 CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29cd40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Config overrides:\n",
      "   ℹ️  No overrides - using config from YAML file\n",
      "   💡 Uncomment lines above to override config values\n",
      "\n",
      "📋 Current configuration:\n",
      "   - Experiment: thai_auto\n",
      "   - Iterations: 5,000\n",
      "   - Batch size: 8\n",
      "   - Learning rate: 0.001\n",
      "   - Workers: 0\n",
      "   - Device: cpu\n",
      "\n",
      "💡 วิธีใช้:\n",
      "   1. Uncomment บรรทัดที่ต้องการแก้ไข (ลบ # หน้าบรรทัด)\n",
      "   2. ใส่ค่าที่ต้องการ\n",
      "   3. Run cell นี้ใหม่\n",
      "   4. ตัวอย่าง: 'batch_size': 8, 'num_iter': 10000\n"
     ]
    }
   ],
   "source": [
    "# 🔧 CONFIG OVERRIDES\n",
    "# รวมทุกการตั้งค่าไว้ในที่เดียว - ไม่ต้องแก้ไฟล์ YAML!\n",
    "\n",
    "CONFIG_OVERRIDES = {\n",
    "    # 📁 เส้นทางข้อมูล\n",
    "    # 'train_data': '/Users/puem/Downloads/thai_lang_ocr_dataset',\n",
    "    # 'valid_data': '/Users/puem/Downloads/thai_lang_ocr_dataset', \n",
    "    # 'select_data': '0',\n",
    "    \n",
    "    # 🏋️ การฝึกสอน\n",
    "    # 'experiment_name': 'my_thai_ocr_v3',\n",
    "    # 'num_iter': 15000,\n",
    "    # 'batch_size': 16,\n",
    "    # 'lr': 0.001,\n",
    "    # 'workers': 4,\n",
    "    \n",
    "    # 🤖 โมเดล\n",
    "    # 'saved_model': '',  # Resume from checkpoint\n",
    "    # 'batch_max_length': 100,\n",
    "}\n",
    "\n",
    "# นำค่าที่แก้ไขไปใช้\n",
    "overrides_applied = 0\n",
    "for key, value in CONFIG_OVERRIDES.items():\n",
    "    if value is not None and value != '':\n",
    "        setattr(opt, key, value)\n",
    "        overrides_applied += 1\n",
    "\n",
    "if overrides_applied > 0:\n",
    "    print(f\"✏️  Applied {overrides_applied} config overrides\")\n",
    "else:\n",
    "    print(\"ℹ️  Using default config (uncomment lines above to override)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9508e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "⚙️ CONFIGURATION SUMMARY: thai_auto\n",
      "==================================================\n",
      "  - Training iterations: 5,000\n",
      "  - Batch size: 8\n",
      "  - Learning rate: 0.001\n",
      "  - Workers: 0\n",
      "  - Target device: cpu\n",
      "  - Character set: 92 characters\n",
      "    - Numbers: 10, Symbols: 34, Thai: 48\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"⚙️  {opt.experiment_name}\")\n",
    "print(f\"🔢 Iterations: {opt.num_iter:,} | Batch: {opt.batch_size} | LR: {opt.lr}\")\n",
    "print(f\"🎯 Device: {opt.device} | Workers: {opt.workers}\")\n",
    "print(f\"🔤 Characters: {len(opt.character)} total\")\n",
    "\n",
    "if opt.batch_size > 16:\n",
    "    print(f\"⚠️  Large batch_size - reduce if out of memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da8372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Fixing dataset paths based on directory structure...\n",
      "✅ thai_train: OK (99995 images found)\n",
      "✅ thai_train: OK (99995 images found)\n",
      "✅ thai_val: OK (100000 images found)\n",
      "✅ Training labels: OK (197995 entries)\n",
      "✅ Validation labels: OK (2000 entries)\n",
      "\n",
      "🎯 Result: ✅ Ready to train!\n",
      "\n",
      "📁 Dataset structure confirmed:\n",
      "   Base: /Users/puem/Downloads/thai_lang_ocr_dataset\n",
      "   Train images: folder '0'\n",
      "   Val images: folder '1'\n",
      "   Labels: train_list.txt & val_list.txt\n",
      "✅ thai_val: OK (100000 images found)\n",
      "✅ Training labels: OK (197995 entries)\n",
      "✅ Validation labels: OK (2000 entries)\n",
      "\n",
      "🎯 Result: ✅ Ready to train!\n",
      "\n",
      "📁 Dataset structure confirmed:\n",
      "   Base: /Users/puem/Downloads/thai_lang_ocr_dataset\n",
      "   Train images: folder '0'\n",
      "   Val images: folder '1'\n",
      "   Labels: train_list.txt & val_list.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"🔧 Fixing dataset paths based on directory structure...\")\n",
    "DATASET_BASE = \"/Users/puem/Downloads/thai_lang_ocr_dataset\"\n",
    "REQUIRED_PATHS = {\n",
    "    'train_images': os.path.join(DATASET_BASE, \"0\"),\n",
    "    'val_images': os.path.join(DATASET_BASE, \"1\"),\n",
    "    'train_labels': os.path.join(DATASET_BASE, \"train_list.txt\"),\n",
    "    'val_labels': os.path.join(DATASET_BASE, \"val_list.txt\")\n",
    "}\n",
    "\n",
    "all_good = True\n",
    "for name, path in REQUIRED_PATHS.items():\n",
    "    if os.path.exists(path):\n",
    "        if 'images' in name:\n",
    "            count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"✅ {name}: {count} images\")\n",
    "        else:\n",
    "            with open(path, 'r', encoding='utf8') as f:\n",
    "                count = len(f.readlines())\n",
    "            print(f\"✅ {name}: {count} entries\")\n",
    "    else:\n",
    "        print(f\"❌ {name}: Not found\")\n",
    "        all_good = False\n",
    "\n",
    "print(f\"\\n🎯 Dataset: {'✅ Ready' if all_good else '❌ Fix paths'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c228dd74",
   "metadata": {},
   "source": [
    "## 📊 VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30132308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting training at: 2025-06-29 03:04:19\n",
      "📊 Training samples to show: 3\n",
      "⚡ Mixed precision (AMP): Disabled\n",
      "🆕 Starting training from scratch\n",
      "\n",
      "==================================================\n",
      "TRAINING LOG\n",
      "==================================================\n",
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: all_data\n",
      "opt.select_data: ['thai_train']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data\t dataset: thai_train\n",
      "all_data/thai_train\n",
      "sub-directory:\t/thai_train\t num samples: 80\n",
      "num total samples of thai_train: 80 x 1.0 (total_data_usage_ratio) = 80\n",
      "num samples of thai_train per batch: 8 x 1.0 (batch_ratio) = 8\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 8 = 8\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data/thai_val\t dataset: /\n",
      "all_data/thai_val/\n",
      "sub-directory:\t/.\t num samples: 20\n",
      "--------------------------------------------------------------------------------\n",
      "No Transformation module specified\n",
      "model input parameters 64 400 20 1 256 256 93 30 None VGG BiLSTM CTC\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (FeatureExtraction): VGG_FeatureExtractor(\n",
      "      (ConvNet): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): ReLU(inplace=True)\n",
      "        (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): ReLU(inplace=True)\n",
      "        (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "        (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (13): ReLU(inplace=True)\n",
      "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (16): ReLU(inplace=True)\n",
      "        (17): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "        (18): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "        (19): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): Linear(in_features=256, out_features=93, bias=True)\n",
      "  )\n",
      ")\n",
      "Modules, Parameters\n",
      "module.FeatureExtraction.ConvNet.0.weight 288\n",
      "module.FeatureExtraction.ConvNet.0.bias 32\n",
      "module.FeatureExtraction.ConvNet.3.weight 18432\n",
      "module.FeatureExtraction.ConvNet.3.bias 64\n",
      "module.FeatureExtraction.ConvNet.6.weight 73728\n",
      "module.FeatureExtraction.ConvNet.6.bias 128\n",
      "module.FeatureExtraction.ConvNet.8.weight 147456\n",
      "module.FeatureExtraction.ConvNet.8.bias 128\n",
      "module.FeatureExtraction.ConvNet.11.weight 294912\n",
      "module.FeatureExtraction.ConvNet.12.weight 256\n",
      "module.FeatureExtraction.ConvNet.12.bias 256\n",
      "module.FeatureExtraction.ConvNet.14.weight 589824\n",
      "module.FeatureExtraction.ConvNet.15.weight 256\n",
      "module.FeatureExtraction.ConvNet.15.bias 256\n",
      "module.FeatureExtraction.ConvNet.18.weight 262144\n",
      "module.FeatureExtraction.ConvNet.18.bias 256\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.0.linear.weight 131072\n",
      "module.SequenceModeling.0.linear.bias 256\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.1.linear.weight 131072\n",
      "module.SequenceModeling.1.linear.bias 256\n",
      "module.Prediction.weight 23808\n",
      "module.Prediction.bias 93\n",
      "Total Trainable Params: 3780317\n",
      "Trainable params num :  3780317\n",
      "Optimizer:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "------------ Options -------------\n",
      "number: 0123456789\n",
      "symbol: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ €\n",
      "lang_char: กขคงจชซญณดตถทธนบปผฝพฟมยรลวศสหอะัาำิีึืุูเแโใไ็่้\n",
      "experiment_name: thai_auto\n",
      "train_data: all_data\n",
      "valid_data: all_data/thai_val\n",
      "manualSeed: 1111\n",
      "workers: 0\n",
      "batch_size: 8\n",
      "num_iter: 5000\n",
      "valInterval: 250\n",
      "saved_model: \n",
      "FT: False\n",
      "optim: adam\n",
      "lr: 0.001\n",
      "beta1: 0.9\n",
      "rho: 0.95\n",
      "eps: 1e-08\n",
      "grad_clip: 5\n",
      "select_data: ['thai_train']\n",
      "batch_ratio: ['1']\n",
      "total_data_usage_ratio: 1.0\n",
      "batch_max_length: 30\n",
      "imgH: 64\n",
      "imgW: 400\n",
      "rgb: False\n",
      "contrast_adjust: 0.0\n",
      "sensitive: True\n",
      "PAD: True\n",
      "data_filtering_off: False\n",
      "Transformation: None\n",
      "FeatureExtraction: VGG\n",
      "SequenceModeling: BiLSTM\n",
      "Prediction: CTC\n",
      "num_fiducial: 20\n",
      "input_channel: 1\n",
      "output_channel: 256\n",
      "hidden_size: 256\n",
      "decode: greedy\n",
      "new_prediction: False\n",
      "freeze_FeatureFxtraction: False\n",
      "freeze_SequenceModeling: False\n",
      "character: 0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ €กขคงจชซญณดตถทธนบปผฝพฟมยรลวศสหอะัาำิีึืุูเแโใไ็่้\n",
      "device: cpu\n",
      "num_class: 93\n",
      "---------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puem/Desktop/tmp/EasyOCR/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/puem/Desktop/tmp/EasyOCR/trainer/train.py:173: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/Users/puem/Desktop/tmp/EasyOCR/.venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/puem/Desktop/tmp/EasyOCR/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/puem/Desktop/tmp/EasyOCR/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️  Training interrupted by user (Ctrl+C)\n",
      "Model checkpoints are saved in: ./saved_models/thai_auto/\n",
      "\n",
      "🏁 Training session ended at: 2025-06-29 03:04:56\n"
     ]
    }
   ],
   "source": [
    "# 🚀 TRAINING\n",
    "use_amp = False  # Mixed precision for faster training\n",
    "show_samples = 3  # Number of samples to show during validation\n",
    "\n",
    "print(f\"🚀 Starting: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"⚡ AMP: {'On' if use_amp else 'Off'} | Samples: {show_samples}\")\n",
    "\n",
    "if opt.saved_model and opt.saved_model != '':\n",
    "    print(f\"🔄 Resuming from: {opt.saved_model}\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    train(opt, show_number=show_samples, amp=use_amp)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n⚠️  Training interrupted (Ctrl+C)\")\n",
    "    print(f\"💾 Models saved in: ./saved_models/{opt.experiment_name}/\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Training failed: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    print(f\"\\n🏁 Ended: {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a72199",
   "metadata": {},
   "source": [
    "## 🚀 TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 MONITORING TOOLS\n",
    "def check_progress(experiment_name):\n",
    "    \"\"\"Check training progress\"\"\"\n",
    "    log_dir = f\"./saved_models/{experiment_name}\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        print(f\"❌ No logs: {log_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Check models\n",
    "    models = [f for f in os.listdir(log_dir) if f.endswith('.pth')]\n",
    "    if models:\n",
    "        print(f\"💾 {len(models)} models saved\")\n",
    "        for model in sorted(models)[-2:]:  # Last 2\n",
    "            size_mb = os.path.getsize(os.path.join(log_dir, model)) / (1024*1024)\n",
    "            print(f\"   {model} ({size_mb:.1f}MB)\")\n",
    "    \n",
    "    # Check log\n",
    "    log_file = os.path.join(log_dir, \"log_train.txt\")\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, 'r', encoding='utf8') as f:\n",
    "            lines = f.readlines()\n",
    "        if lines:\n",
    "            print(f\"📄 Last log: {lines[-1].strip()}\")\n",
    "\n",
    "def quick_log(experiment_name, lines=3):\n",
    "    \"\"\"Show recent log lines\"\"\"\n",
    "    log_file = f\"./saved_models/{experiment_name}/log_train.txt\"\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, 'r', encoding='utf8') as f:\n",
    "            log_lines = f.readlines()\n",
    "        for line in log_lines[-lines:]:\n",
    "            print(line.strip())\n",
    "    else:\n",
    "        print(\"❌ No log found\")\n",
    "\n",
    "print(\"📊 Use: check_progress(opt.experiment_name) | quick_log(opt.experiment_name)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa710f18",
   "metadata": {},
   "source": [
    "## 📊 MONITORING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
