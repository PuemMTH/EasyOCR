{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4a8929",
   "metadata": {},
   "source": [
    "# EasyOCR Thai Training Notebook\n",
    "\n",
    "**Quick Setup:**\n",
    "1. Config ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô \"üîß CONFIG\" \n",
    "2. Check dataset ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô \"üìä VALIDATION\"\n",
    "3. Start training ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô \"üöÄ TRAINING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92115e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# ‚öôÔ∏è SETUP & IMPORTS\n",
    "import os, sys, time, torch, yaml, pandas as pd, numpy as np\n",
    "from datetime import datetime\n",
    "import torch.backends.cudnn as cudnn\n",
    "from train import train\n",
    "from utils import AttrDict\n",
    "\n",
    "# Configure CUDNN for performance\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False\n",
    "\n",
    "# Quick system check\n",
    "print(f\"üêç PyTorch: {torch.__version__}\")\n",
    "print(f\"üî• CUDA: {'‚úÖ' if torch.cuda.is_available() else '‚ùå'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üì± GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef34d4",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è SYSTEM SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940816ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No CUDA available, using CPU\n",
      "üéØ Final device: cpu\n"
     ]
    }
   ],
   "source": [
    "# üéØ GPU SELECTION\n",
    "if torch.cuda.is_available():\n",
    "    GPU_ID = 0  # üîß CHANGE THIS TO SELECT DIFFERENT GPU\n",
    "    device = torch.device(f'cuda:{GPU_ID}')\n",
    "    torch.cuda.set_device(GPU_ID)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"‚úÖ Using GPU {GPU_ID}: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"‚ö†Ô∏è  Using CPU (no CUDA available)\")\n",
    "print(f\"üéØ Final device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù LOAD BASE CONFIG\n",
    "config_file = 'config_files/thai_auto_config.yaml'\n",
    "\n",
    "with open(config_file, 'r', encoding='utf8') as f:\n",
    "    opt = AttrDict(yaml.safe_load(f))\n",
    "\n",
    "# Auto-generate character set from training data\n",
    "all_chars = set()\n",
    "labels_path = os.path.join(opt.train_data, opt.select_data, 'labels.csv')\n",
    "if os.path.exists(labels_path):\n",
    "    df = pd.read_csv(labels_path, sep='^([^,]+),', engine='python', \n",
    "                     usecols=['filename', 'words'], keep_default_na=False)\n",
    "    for text in df['words']:\n",
    "        all_chars.update(text)\n",
    "\n",
    "# Build complete character set\n",
    "numbers = opt.get('number', '')\n",
    "symbols = opt.get('symbol', '')\n",
    "opt.character = numbers + symbols + ''.join(sorted(list(all_chars)))\n",
    "opt.device = str(device)\n",
    "\n",
    "print(f\"üìã Base config loaded: {opt.experiment_name}\")\n",
    "print(f\"üî§ Character set: {len(opt.character)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592692a",
   "metadata": {},
   "source": [
    "## üîß CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29cd40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Config overrides:\n",
      "   ‚ÑπÔ∏è  No overrides - using config from YAML file\n",
      "   üí° Uncomment lines above to override config values\n",
      "\n",
      "üìã Current configuration:\n",
      "   - Experiment: thai_auto\n",
      "   - Iterations: 5,000\n",
      "   - Batch size: 8\n",
      "   - Learning rate: 0.001\n",
      "   - Workers: 0\n",
      "   - Device: cpu\n",
      "\n",
      "üí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:\n",
      "   1. Uncomment ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç (‡∏•‡∏ö # ‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)\n",
      "   2. ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
      "   3. Run cell ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡∏°‡πà\n",
      "   4. ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: 'batch_size': 8, 'num_iter': 10000\n"
     ]
    }
   ],
   "source": [
    "# üîß CONFIG OVERRIDES\n",
    "# ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏ü‡∏•‡πå YAML!\n",
    "\n",
    "CONFIG_OVERRIDES = {\n",
    "    # üìÅ ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    # 'train_data': '/Users/puem/Downloads/thai_lang_ocr_dataset',\n",
    "    # 'valid_data': '/Users/puem/Downloads/thai_lang_ocr_dataset', \n",
    "    # 'select_data': '0',\n",
    "    \n",
    "    # üèãÔ∏è ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô\n",
    "    # 'experiment_name': 'my_thai_ocr_v3',\n",
    "    # 'num_iter': 15000,\n",
    "    # 'batch_size': 16,\n",
    "    # 'lr': 0.001,\n",
    "    # 'workers': 4,\n",
    "    \n",
    "    # ü§ñ ‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "    # 'saved_model': '',  # Resume from checkpoint\n",
    "    # 'batch_max_length': 100,\n",
    "}\n",
    "\n",
    "# ‡∏ô‡∏≥‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏õ‡πÉ‡∏ä‡πâ\n",
    "overrides_applied = 0\n",
    "for key, value in CONFIG_OVERRIDES.items():\n",
    "    if value is not None and value != '':\n",
    "        setattr(opt, key, value)\n",
    "        overrides_applied += 1\n",
    "\n",
    "if overrides_applied > 0:\n",
    "    print(f\"‚úèÔ∏è  Applied {overrides_applied} config overrides\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Using default config (uncomment lines above to override)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9508e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "‚öôÔ∏è CONFIGURATION SUMMARY: thai_auto\n",
      "==================================================\n",
      "  - Training iterations: 5,000\n",
      "  - Batch size: 8\n",
      "  - Learning rate: 0.001\n",
      "  - Workers: 0\n",
      "  - Target device: cpu\n",
      "  - Character set: 92 characters\n",
      "    - Numbers: 10, Symbols: 34, Thai: 48\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"‚öôÔ∏è  {opt.experiment_name}\")\n",
    "print(f\"üî¢ Iterations: {opt.num_iter:,} | Batch: {opt.batch_size} | LR: {opt.lr}\")\n",
    "print(f\"üéØ Device: {opt.device} | Workers: {opt.workers}\")\n",
    "print(f\"üî§ Characters: {len(opt.character)} total\")\n",
    "\n",
    "if opt.batch_size > 16:\n",
    "    print(f\"‚ö†Ô∏è  Large batch_size - reduce if out of memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da8372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Fixing dataset paths based on directory structure...\n",
      "‚úÖ thai_train: OK (99995 images found)\n",
      "‚úÖ thai_train: OK (99995 images found)\n",
      "‚úÖ thai_val: OK (100000 images found)\n",
      "‚úÖ Training labels: OK (197995 entries)\n",
      "‚úÖ Validation labels: OK (2000 entries)\n",
      "\n",
      "üéØ Result: ‚úÖ Ready to train!\n",
      "\n",
      "üìÅ Dataset structure confirmed:\n",
      "   Base: /Users/puem/Downloads/thai_lang_ocr_dataset\n",
      "   Train images: folder '0'\n",
      "   Val images: folder '1'\n",
      "   Labels: train_list.txt & val_list.txt\n",
      "‚úÖ thai_val: OK (100000 images found)\n",
      "‚úÖ Training labels: OK (197995 entries)\n",
      "‚úÖ Validation labels: OK (2000 entries)\n",
      "\n",
      "üéØ Result: ‚úÖ Ready to train!\n",
      "\n",
      "üìÅ Dataset structure confirmed:\n",
      "   Base: /Users/puem/Downloads/thai_lang_ocr_dataset\n",
      "   Train images: folder '0'\n",
      "   Val images: folder '1'\n",
      "   Labels: train_list.txt & val_list.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Fixing dataset paths based on directory structure...\")\n",
    "DATASET_BASE = \"/Users/puem/Downloads/thai_lang_ocr_dataset\"\n",
    "REQUIRED_PATHS = {\n",
    "    'train_images': os.path.join(DATASET_BASE, \"0\"),\n",
    "    'val_images': os.path.join(DATASET_BASE, \"1\"),\n",
    "    'train_labels': os.path.join(DATASET_BASE, \"train_list.txt\"),\n",
    "    'val_labels': os.path.join(DATASET_BASE, \"val_list.txt\")\n",
    "}\n",
    "\n",
    "all_good = True\n",
    "for name, path in REQUIRED_PATHS.items():\n",
    "    if os.path.exists(path):\n",
    "        if 'images' in name:\n",
    "            count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"‚úÖ {name}: {count} images\")\n",
    "        else:\n",
    "            with open(path, 'r', encoding='utf8') as f:\n",
    "                count = len(f.readlines())\n",
    "            print(f\"‚úÖ {name}: {count} entries\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name}: Not found\")\n",
    "        all_good = False\n",
    "\n",
    "print(f\"\\nüéØ Dataset: {'‚úÖ Ready' if all_good else '‚ùå Fix paths'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c228dd74",
   "metadata": {},
   "source": [
    "## üìä VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30132308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training at: 2025-06-29 03:04:19\n",
      "üìä Training samples to show: 3\n",
      "‚ö° Mixed precision (AMP): Disabled\n",
      "üÜï Starting training from scratch\n",
      "\n",
      "==================================================\n",
      "TRAINING LOG\n",
      "==================================================\n",
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: all_data\n",
      "opt.select_data: ['thai_train']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data\t dataset: thai_train\n",
      "all_data/thai_train\n",
      "sub-directory:\t/thai_train\t num samples: 80\n",
      "num total samples of thai_train: 80 x 1.0 (total_data_usage_ratio) = 80\n",
      "num samples of thai_train per batch: 8 x 1.0 (batch_ratio) = 8\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 8 = 8\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data/thai_val\t dataset: /\n",
      "all_data/thai_val/\n",
      "sub-directory:\t/.\t num samples: 20\n",
      "--------------------------------------------------------------------------------\n",
      "No Transformation module specified\n",
      "model input parameters 64 400 20 1 256 256 93 30 None VGG BiLSTM CTC\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (FeatureExtraction): VGG_FeatureExtractor(\n",
      "      (ConvNet): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): ReLU(inplace=True)\n",
      "        (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): ReLU(inplace=True)\n",
      "        (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "        (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (13): ReLU(inplace=True)\n",
      "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (16): ReLU(inplace=True)\n",
      "        (17): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "        (18): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "        (19): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): Linear(in_features=256, out_features=93, bias=True)\n",
      "  )\n",
      ")\n",
      "Modules, Parameters\n",
      "module.FeatureExtraction.ConvNet.0.weight 288\n",
      "module.FeatureExtraction.ConvNet.0.bias 32\n",
      "module.FeatureExtraction.ConvNet.3.weight 18432\n",
      "module.FeatureExtraction.ConvNet.3.bias 64\n",
      "module.FeatureExtraction.ConvNet.6.weight 73728\n",
      "module.FeatureExtraction.ConvNet.6.bias 128\n",
      "module.FeatureExtraction.ConvNet.8.weight 147456\n",
      "module.FeatureExtraction.ConvNet.8.bias 128\n",
      "module.FeatureExtraction.ConvNet.11.weight 294912\n",
      "module.FeatureExtraction.ConvNet.12.weight 256\n",
      "module.FeatureExtraction.ConvNet.12.bias 256\n",
      "module.FeatureExtraction.ConvNet.14.weight 589824\n",
      "module.FeatureExtraction.ConvNet.15.weight 256\n",
      "module.FeatureExtraction.ConvNet.15.bias 256\n",
      "module.FeatureExtraction.ConvNet.18.weight 262144\n",
      "module.FeatureExtraction.ConvNet.18.bias 256\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.0.linear.weight 131072\n",
      "module.SequenceModeling.0.linear.bias 256\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.1.linear.weight 131072\n",
      "module.SequenceModeling.1.linear.bias 256\n",
      "module.Prediction.weight 23808\n",
      "module.Prediction.bias 93\n",
      "Total Trainable Params: 3780317\n",
      "Trainable params num :  3780317\n",
      "Optimizer:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "------------ Options -------------\n",
      "number: 0123456789\n",
      "symbol: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ ‚Ç¨\n",
      "lang_char: ‡∏Å‡∏Ç‡∏Ñ‡∏á‡∏à‡∏ä‡∏ã‡∏ç‡∏ì‡∏î‡∏ï‡∏ñ‡∏ó‡∏ò‡∏ô‡∏ö‡∏õ‡∏ú‡∏ù‡∏û‡∏ü‡∏°‡∏¢‡∏£‡∏•‡∏ß‡∏®‡∏™‡∏´‡∏≠‡∏∞‡∏±‡∏≤‡∏≥‡∏¥‡∏µ‡∏∂‡∏∑‡∏∏‡∏π‡πÄ‡πÅ‡πÇ‡πÉ‡πÑ‡πá‡πà‡πâ\n",
      "experiment_name: thai_auto\n",
      "train_data: all_data\n",
      "valid_data: all_data/thai_val\n",
      "manualSeed: 1111\n",
      "workers: 0\n",
      "batch_size: 8\n",
      "num_iter: 5000\n",
      "valInterval: 250\n",
      "saved_model: \n",
      "FT: False\n",
      "optim: adam\n",
      "lr: 0.001\n",
      "beta1: 0.9\n",
      "rho: 0.95\n",
      "eps: 1e-08\n",
      "grad_clip: 5\n",
      "select_data: ['thai_train']\n",
      "batch_ratio: ['1']\n",
      "total_data_usage_ratio: 1.0\n",
      "batch_max_length: 30\n",
      "imgH: 64\n",
      "imgW: 400\n",
      "rgb: False\n",
      "contrast_adjust: 0.0\n",
      "sensitive: True\n",
      "PAD: True\n",
      "data_filtering_off: False\n",
      "Transformation: None\n",
      "FeatureExtraction: VGG\n",
      "SequenceModeling: BiLSTM\n",
      "Prediction: CTC\n",
      "num_fiducial: 20\n",
      "input_channel: 1\n",
      "output_channel: 256\n",
      "hidden_size: 256\n",
      "decode: greedy\n",
      "new_prediction: False\n",
      "freeze_FeatureFxtraction: False\n",
      "freeze_SequenceModeling: False\n",
      "character: 0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ ‚Ç¨‡∏Å‡∏Ç‡∏Ñ‡∏á‡∏à‡∏ä‡∏ã‡∏ç‡∏ì‡∏î‡∏ï‡∏ñ‡∏ó‡∏ò‡∏ô‡∏ö‡∏õ‡∏ú‡∏ù‡∏û‡∏ü‡∏°‡∏¢‡∏£‡∏•‡∏ß‡∏®‡∏™‡∏´‡∏≠‡∏∞‡∏±‡∏≤‡∏≥‡∏¥‡∏µ‡∏∂‡∏∑‡∏∏‡∏π‡πÄ‡πÅ‡πÇ‡πÉ‡πÑ‡πá‡πà‡πâ\n",
      "device: cpu\n",
      "num_class: 93\n",
      "---------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puem/Desktop/tmp/EasyOCR/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/puem/Desktop/tmp/EasyOCR/trainer/train.py:173: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/Users/puem/Desktop/tmp/EasyOCR/.venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/puem/Desktop/tmp/EasyOCR/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/puem/Desktop/tmp/EasyOCR/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è  Training interrupted by user (Ctrl+C)\n",
      "Model checkpoints are saved in: ./saved_models/thai_auto/\n",
      "\n",
      "üèÅ Training session ended at: 2025-06-29 03:04:56\n"
     ]
    }
   ],
   "source": [
    "# üöÄ TRAINING\n",
    "use_amp = False  # Mixed precision for faster training\n",
    "show_samples = 3  # Number of samples to show during validation\n",
    "\n",
    "print(f\"üöÄ Starting: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"‚ö° AMP: {'On' if use_amp else 'Off'} | Samples: {show_samples}\")\n",
    "\n",
    "if opt.saved_model and opt.saved_model != '':\n",
    "    print(f\"üîÑ Resuming from: {opt.saved_model}\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    train(opt, show_number=show_samples, amp=use_amp)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è  Training interrupted (Ctrl+C)\")\n",
    "    print(f\"üíæ Models saved in: ./saved_models/{opt.experiment_name}/\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    print(f\"\\nüèÅ Ended: {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a72199",
   "metadata": {},
   "source": [
    "## üöÄ TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä MONITORING TOOLS\n",
    "def check_progress(experiment_name):\n",
    "    \"\"\"Check training progress\"\"\"\n",
    "    log_dir = f\"./saved_models/{experiment_name}\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        print(f\"‚ùå No logs: {log_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Check models\n",
    "    models = [f for f in os.listdir(log_dir) if f.endswith('.pth')]\n",
    "    if models:\n",
    "        print(f\"üíæ {len(models)} models saved\")\n",
    "        for model in sorted(models)[-2:]:  # Last 2\n",
    "            size_mb = os.path.getsize(os.path.join(log_dir, model)) / (1024*1024)\n",
    "            print(f\"   {model} ({size_mb:.1f}MB)\")\n",
    "    \n",
    "    # Check log\n",
    "    log_file = os.path.join(log_dir, \"log_train.txt\")\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, 'r', encoding='utf8') as f:\n",
    "            lines = f.readlines()\n",
    "        if lines:\n",
    "            print(f\"üìÑ Last log: {lines[-1].strip()}\")\n",
    "\n",
    "def quick_log(experiment_name, lines=3):\n",
    "    \"\"\"Show recent log lines\"\"\"\n",
    "    log_file = f\"./saved_models/{experiment_name}/log_train.txt\"\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, 'r', encoding='utf8') as f:\n",
    "            log_lines = f.readlines()\n",
    "        for line in log_lines[-lines:]:\n",
    "            print(line.strip())\n",
    "    else:\n",
    "        print(\"‚ùå No log found\")\n",
    "\n",
    "print(\"üìä Use: check_progress(opt.experiment_name) | quick_log(opt.experiment_name)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa710f18",
   "metadata": {},
   "source": [
    "## üìä MONITORING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
